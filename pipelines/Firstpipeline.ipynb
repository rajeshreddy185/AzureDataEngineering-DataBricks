{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e0f101-16fe-4fa1-937e-b02f32de9a5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1 in 01_Bronze\n",
    "%run _resources/setup_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952f7ab6-50db-404b-9b98-bc0d028766c0",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1771066775061}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Save to your container\n",
    "\n",
    "path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/inbound/loan.csv\"\n",
    "\n",
    "df = spark.read.csv(path, header=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c668f2d-3b4c-4550-ba1e-e7f794de0176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "# 1 = Defaulter, 0 = Good Payer\n",
    "\n",
    "df = df.withColumn(\"is_bad_loan\", \n",
    "    when(col(\"loan_status\").isin(\"Charged Off\", \"Default\", \"Late (31-120 days)\"), 1)\n",
    "    .otherwise(0)\n",
    ")\n",
    "display(df.filter(df.is_bad_loan == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61476573-1c90-4f36-a47b-984709f74f94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "delta_path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/outbound/\"\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
    "\n",
    "print(f\"Success! Data written to Delta at: {delta_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb2bc280-572a-4dc8-8636-def5d5dc48c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "access_key = dbutils.secrets.get(scope='adlsgen2storageaccesskey', key='storageadlsgen2accesskey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da61623f-66ab-4078-98ff-d354ebf8b575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_account_name = 'rjdatalakestorage01'\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\", \n",
    "    access_key\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Save to your container\n",
    "container_name = \"databrickscontainer01\"\n",
    "path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/inbound/loan.csv\"\n",
    "\n",
    "df = spark.read.csv(path, header=True)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Firstpipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
